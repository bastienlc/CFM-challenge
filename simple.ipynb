{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestRegressor,\n",
    "    RandomForestClassifier,\n",
    "    StackingRegressor,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from src.utils import save\n",
    "\n",
    "verbose = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Inspired by Franck Zibi's model :\n",
    "Level 0 : Extract features from the series of data\n",
    "Level 1 : Base classification with GradientBoostingClassifier\n",
    "Level 2 : Residual estimation of the probabilities with ensemble of models\n",
    "    - For each category\n",
    "        - RandomForestRegressor\n",
    "        - KNeighborsRegressor\n",
    "        - MLPRegressor\n",
    "        - SVR\n",
    "Level 3 : Stacking of the residual estimations\n",
    "    - For each category\n",
    "        - StackingRegressor with GradientBoostingRegressor\n",
    "Level 4 : Nothing for now, but calibration on the test set could be done\n",
    "\"\"\"\n",
    "\n",
    "# Level 1\n",
    "\n",
    "base_classifier = RandomForestClassifier(verbose=verbose, n_jobs=18)\n",
    "\n",
    "# Level 2\n",
    "regressors = []\n",
    "for _ in range(24):\n",
    "    regressors.append(\n",
    "        [\n",
    "            (\n",
    "                \"RandomForestRegressor\",\n",
    "                RandomForestRegressor(verbose=verbose, n_jobs=18),\n",
    "            ),\n",
    "            (\"KNeighborsRegressor\", KNeighborsRegressor(n_jobs=18)),\n",
    "            (\"LinearRegression\", LinearRegression(n_jobs=18)),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "# Level 3\n",
    "stacking_regressors = []\n",
    "for k in range(24):\n",
    "    stacking_regressors.append(\n",
    "        StackingRegressor(\n",
    "            estimators=regressors[k],\n",
    "            final_estimator=LinearRegression(n_jobs=18),\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_parquet(f\"data/features_train.parquet\")\n",
    "y_train = pd.read_csv(\"data/y_train.csv\")\n",
    "X_test = pd.read_parquet(f\"data/features_test.parquet\")\n",
    "\n",
    "X_train = X_train.values[:, 1:]\n",
    "y_train = y_train.values[:, 1]\n",
    "X_test = X_test.values[:, 1:]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1)\n",
    "\n",
    "print(X_train.shape, X_val.shape, y_train.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_y_val = np.eye(np.max(y_val) + 1)[y_val]\n",
    "one_hot_y_train = np.eye(np.max(y_train) + 1)[y_train]\n",
    "\n",
    "print(\"Training base classifier...\")\n",
    "base_classifier.fit(X_train, y_train)\n",
    "\n",
    "y_train_residuals = one_hot_y_train - base_classifier.predict_proba(X_train)\n",
    "\n",
    "for k in range(24):\n",
    "    print(f\"Training regressor {k}...\")\n",
    "    stacking_regressors[k].fit(X_train, y_train_residuals[:, k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"runs/simple/base_classifier.pkl\", \"wb\") as f:\n",
    "    pickle.dump(base_classifier, f)\n",
    "\n",
    "for k in range(24):\n",
    "    with open(f\"runs/simple/stacking_regressor_{k}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(stacking_regressors[k], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"runs/simple/base_classifier.pkl\", \"rb\") as f:\n",
    "    base_classifier = pickle.load(f)\n",
    "\n",
    "for k in range(24):\n",
    "    with open(f\"runs/simple/stacking_regressor_{k}.pkl\", \"rb\") as f:\n",
    "        stacking_regressors[k] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_base_pred = base_classifier.predict_proba(X_val)\n",
    "y_val_residuals = np.zeros_like(y_val_base_pred)\n",
    "for k in range(24):\n",
    "    y_val_residuals[:, k] = stacking_regressors[k].predict(X_val)\n",
    "y_val_pred = y_val_base_pred + y_val_residuals\n",
    "np.save(\"runs/simple/val_predictions.npy\", y_val_pred)\n",
    "y_val_pred = np.argmax(y_val_pred, axis=1)\n",
    "\n",
    "print(\"Validation accuracy:\", (y_val_pred == y_val).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_base_pred = base_classifier.predict_proba(X_test)\n",
    "y_test_residuals = np.zeros_like(y_test_base_pred)\n",
    "for k in range(24):\n",
    "    y_test_residuals[:, k] = stacking_regressors[k].predict(X_test)\n",
    "y_test_pred = y_test_base_pred + y_test_residuals\n",
    "np.save(\"runs/simple/test_predictions.npy\", y_test_pred)\n",
    "y_test_pred = np.argmax(y_test_pred, axis=1)\n",
    "\n",
    "save(y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_base_pred = base_classifier.predict_proba(X_train)\n",
    "y_train_residuals = np.zeros_like(y_train_base_pred)\n",
    "for k in range(24):\n",
    "    y_train_residuals[:, k] = stacking_regressors[k].predict(X_train)\n",
    "y_train_pred = y_train_base_pred + y_train_residuals\n",
    "np.save(\"runs/simple/train_predictions.npy\", y_train_pred)\n",
    "\n",
    "print(\"Training accuracy:\", (np.argmax(y_train_pred, axis=1) == y_train).mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "altegrad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

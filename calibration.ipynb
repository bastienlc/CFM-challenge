{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from src.datasets import CFMGraphDataset\n",
    "from src.loaders import get_test_loader, get_train_loaders\n",
    "from src.models import GATEncoder\n",
    "from src.utils import predict, save\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Data\n",
    "train_loader, val_loader = get_train_loaders(\n",
    "    batch_size=128, shuffle=False, dataset=CFMGraphDataset\n",
    ")\n",
    "test_loader = get_test_loader(batch_size=128, dataset=CFMGraphDataset)\n",
    "is_torch_geometric = True\n",
    "\n",
    "model = GATEncoder(\n",
    "    d_features=7,\n",
    "    d_edges=5,\n",
    "    d_out=24,\n",
    "    d_hidden_dim=300,\n",
    "    num_layers=3,\n",
    "    num_heads=3,\n",
    "    d_linear_layers=[256],\n",
    "    dropout=0.01,\n",
    "    activation=\"ReLU\",\n",
    ").to(device)\n",
    "\n",
    "load = \"runs/night_test\"\n",
    "\n",
    "model.load_state_dict(torch.load(f\"{load}/model.pt\"))\n",
    "\n",
    "# Test prediction\n",
    "test_y_pred, _, test_probas = predict(\n",
    "    model, test_loader, device, is_torch_geometric=is_torch_geometric\n",
    ")\n",
    "save(test_y_pred, \"solution.csv\")\n",
    "\n",
    "# Score on validation set\n",
    "val_y_pred, val_y_true, val_probas = predict(\n",
    "    model, val_loader, device, is_torch_geometric=is_torch_geometric\n",
    ")\n",
    "print(\"Validation accuracy:\", (val_y_pred == val_y_true).mean())\n",
    "\n",
    "# Score on full training set\n",
    "train_y_pred, train_y_true, train_probas = predict(\n",
    "    model, train_loader, device, is_torch_geometric=is_torch_geometric\n",
    ")\n",
    "print(\"Train accuracy:\", (train_y_pred == train_y_true).mean())\n",
    "\n",
    "# Accuracies for each class\n",
    "val_accuracies = []\n",
    "for i in range(24):\n",
    "    val_accuracies.append((val_y_pred[val_y_true == i] == i).mean())\n",
    "train_accuracies = []\n",
    "for i in range(24):\n",
    "    train_accuracies.append((train_y_pred[train_y_true == i] == i).mean())\n",
    "\n",
    "width = 0.2\n",
    "plt.bar(np.arange(24) - width, val_accuracies, label=\"val\", width=width)\n",
    "plt.bar(np.arange(24) + width, train_accuracies, label=\"train\", width=width)\n",
    "plt.xticks(range(24))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram of the argmax of the probabilities for train, val and test\n",
    "\n",
    "plt.hist(\n",
    "    np.max(train_probas, axis=1),\n",
    "    bins=24,\n",
    "    alpha=0.5,\n",
    "    label=\"train\",\n",
    "    density=True,\n",
    ")\n",
    "plt.hist(\n",
    "    np.max(val_probas, axis=1),\n",
    "    bins=24,\n",
    "    alpha=0.5,\n",
    "    label=\"val\",\n",
    "    density=True,\n",
    ")\n",
    "plt.hist(\n",
    "    np.max(test_probas, axis=1),\n",
    "    bins=24,\n",
    "    alpha=0.5,\n",
    "    label=\"test\",\n",
    "    density=True,\n",
    ")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class distribution\n",
    "plt.hist(train_y_pred, bins=24, alpha=0.5, label=\"train\", density=True)\n",
    "plt.hist(val_y_pred, bins=24, alpha=0.5, label=\"val\", density=True)\n",
    "plt.hist(test_y_pred, bins=24, alpha=0.5, label=\"test\", density=True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from betacal import BetaCalibration\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "\n",
    "K = 3\n",
    "fig, ax = plt.subplots(24 // K, K, figsize=(20, 30))\n",
    "bins = 10\n",
    "strategy = \"uniform\"\n",
    "# for each class\n",
    "for i in range(24):\n",
    "    # Without calibration\n",
    "    val_prob_true, val_prob_pred = calibration_curve(\n",
    "        val_y_true == i,\n",
    "        val_probas[:, i],\n",
    "        n_bins=bins,\n",
    "        strategy=strategy,\n",
    "    )\n",
    "    train_prob_true, train_prob_pred = calibration_curve(\n",
    "        train_y_true == i,\n",
    "        train_probas[:, i],\n",
    "        n_bins=bins,\n",
    "        strategy=strategy,\n",
    "    )\n",
    "    test_prob_true, test_prob_pred = calibration_curve(\n",
    "        test_y_pred == i,\n",
    "        test_probas[:, i],\n",
    "        n_bins=bins,\n",
    "        strategy=strategy,\n",
    "    )\n",
    "\n",
    "    # With beta calibration\n",
    "    calibrator = IsotonicRegression()\n",
    "    calibrator.fit(train_probas[:, i].reshape(-1, 1), (train_y_true == i).astype(int))\n",
    "\n",
    "    val_prob_pred_calibrated = calibrator.predict(val_probas[:, i].reshape(-1, 1))\n",
    "    train_prob_pred_calibrated = calibrator.predict(train_probas[:, i].reshape(-1, 1))\n",
    "    test_prob_pred_calibrated = calibrator.predict(test_probas[:, i].reshape(-1, 1))\n",
    "\n",
    "    cal_val_prob_true, cal_val_prob_pred = calibration_curve(\n",
    "        val_y_true == i,\n",
    "        val_prob_pred_calibrated,\n",
    "        n_bins=bins,\n",
    "        strategy=strategy,\n",
    "    )\n",
    "    cal_train_prob_true, cal_train_prob_pred = calibration_curve(\n",
    "        train_y_true == i,\n",
    "        train_prob_pred_calibrated,\n",
    "        n_bins=bins,\n",
    "        strategy=strategy,\n",
    "    )\n",
    "    cal_test_prob_true, cal_test_prob_pred = calibration_curve(\n",
    "        test_y_pred == i,\n",
    "        test_prob_pred_calibrated,\n",
    "        n_bins=bins,\n",
    "        strategy=strategy,\n",
    "    )\n",
    "\n",
    "    # New\n",
    "    ax[i // K, i % K].plot(\n",
    "        cal_train_prob_pred,\n",
    "        cal_train_prob_true,\n",
    "        marker=\"o\",\n",
    "        label=\"train\",\n",
    "        color=\"blue\",\n",
    "    )\n",
    "    ax[i // K, i % K].plot(\n",
    "        cal_val_prob_pred, cal_val_prob_true, marker=\"o\", label=\"val\", color=\"orange\"\n",
    "    )\n",
    "    ax[i // K, i % K].plot(\n",
    "        cal_test_prob_pred, cal_test_prob_true, marker=\"o\", label=\"test\", color=\"green\"\n",
    "    )\n",
    "    # Old\n",
    "    ax[i // K, i % K].plot(\n",
    "        train_prob_pred,\n",
    "        train_prob_true,\n",
    "        marker=\"o\",\n",
    "        alpha=0.5,\n",
    "        color=\"blue\",\n",
    "    )\n",
    "    ax[i // K, i % K].plot(\n",
    "        val_prob_pred, val_prob_true, marker=\"o\", alpha=0.5, color=\"orange\"\n",
    "    )\n",
    "    ax[i // K, i % K].plot(\n",
    "        test_prob_pred,\n",
    "        test_prob_true,\n",
    "        marker=\"o\",\n",
    "        alpha=0.5,\n",
    "        color=\"green\",\n",
    "    )\n",
    "    ax[i // K, i % K].plot([0, 1], [0, 1], linestyle=\"--\", color=\"black\")\n",
    "    ax[i // K, i % K].set_title(f\"Class {i+1}\")\n",
    "    ax[i // K, i % K].set_xlabel(\"Mean predicted probability\")\n",
    "    ax[i // K, i % K].set_ylabel(\"Fraction of positives\")\n",
    "    ax[i // K, i % K].legend()\n",
    "\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
